#!/usr/bin/env python3
"""
DAWN Tick Orchestrator - Unified Tick Cycle Coordination
========================================================

Coordinate tick cycles across all DAWN subsystems for coherent consciousness.
Provides synchronized execution phases, barrier synchronization, and performance
monitoring to eliminate consciousness fragmentation from unsynchronized updates.
"""

import time
import uuid
import threading
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Tuple, Set
from dataclasses import dataclass, field
from collections import defaultdict, deque
from enum import Enum
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed, Future
import weakref

# Import centralized state management
try:
    from dawn.core.foundation.state import get_state, set_state, clamp, label_for, update_unity_delta, update_awareness_delta
except ImportError:
    from state import get_state, set_state, clamp, label_for, update_unity_delta, update_awareness_delta

logger = logging.getLogger(__name__)

class TickPhase(Enum):
    """Phases of synchronized tick execution."""
    IDLE = "idle"
    STATE_COLLECTION = "state_collection"
    INFORMATION_SHARING = "information_sharing"
    DECISION_MAKING = "decision_making"
    STATE_UPDATES = "state_updates"
    SYNCHRONIZATION_CHECK = "synchronization_check"
    COMPLETED = "completed"
    ERROR = "error"

class ModuleTickStatus(Enum):
    """Status of a module in the current tick."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    TIMEOUT = "timeout"
    ERROR = "error"
    SKIPPED = "skipped"

@dataclass
class ModuleTickResult:
    """Result of a module's tick execution in a specific phase."""
    module_name: str
    phase: TickPhase
    status: ModuleTickStatus
    execution_time: float
    result_data: Dict[str, Any]
    error_message: Optional[str] = None
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class TickExecutionResult:
    """Result of a complete unified tick execution."""
    tick_number: int
    total_execution_time: float
    phase_results: Dict[TickPhase, Dict[str, ModuleTickResult]]
    consciousness_coherence: float
    synchronization_success: bool
    bottlenecks_detected: List[str]
    performance_summary: Dict[str, Any]
    state_consistency_score: float
    decision_consensus_rate: float
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class ModuleRegistration:
    """Registration information for a module in the tick orchestrator."""
    module_name: str
    module_instance: Any
    tick_phases: Set[TickPhase]
    priority: int  # Lower number = higher priority
    timeout_seconds: float
    performance_weight: float  # Weight in bottleneck calculations
    last_performance: Dict[str, float] = field(default_factory=dict)
    error_count: int = 0
    registration_time: datetime = field(default_factory=datetime.now)

class TickOrchestrator:
    """
    Unified tick cycle coordination for coherent consciousness.
    
    Coordinates tick cycles across all DAWN subsystems using synchronized
    execution phases, barrier synchronization, and performance monitoring.
    """
    
    def __init__(self, consciousness_bus=None, consensus_engine=None, 
                 default_timeout: float = 2.0, max_parallel_modules: int = 8):
        """Initialize the tick orchestrator."""
        self.orchestrator_id = str(uuid.uuid4())
        
        # Use DAWN singleton if components not provided
        if consciousness_bus is None or consensus_engine is None:
            try:
                from dawn.core.singleton import get_dawn
                dawn_system = get_dawn()
                
                self.consciousness_bus = consciousness_bus or dawn_system.consciousness_bus
                # Consensus engine might not be available yet, that's ok
                self.consensus_engine = consensus_engine
                self.telemetry_system = dawn_system.telemetry_system
                logger.info("ðŸŒ… Tick orchestrator using DAWN singleton")
            except ImportError:
                logger.warning("DAWN singleton not available")
                self.consciousness_bus = consciousness_bus
                self.consensus_engine = consensus_engine
                self.telemetry_system = None
        else:
            self.consciousness_bus = consciousness_bus
            self.consensus_engine = consensus_engine
            self.telemetry_system = None
            
        self.creation_time = datetime.now()
        
        # Lifecycle control
        self._running = False
        self._tasks = []  # List of asyncio.Task for cancellation
        
        # Module management
        self.modules = {}  # Dict[str, ModuleRegistration]
        self.tick_count = 0
        self.current_phase = TickPhase.IDLE
        self.phase_barriers = {phase: threading.Barrier(1) for phase in TickPhase}
        
        # Configuration
        self.default_timeout = default_timeout
        self.max_parallel_modules = max_parallel_modules
        self.adaptive_timing = True
        self.bottleneck_detection_enabled = True
        
        # State management
        self.current_tick_state = {}  # Collected states from all modules
        self.shared_information = {}  # Information shared between modules
        self.tick_decisions = {}  # Decisions made during tick
        self.execution_lock = threading.RLock()
        
        # Performance tracking
        self.performance_history = deque(maxlen=100)
        self.bottleneck_history = deque(maxlen=50)
        self.phase_timing_history = defaultdict(lambda: deque(maxlen=20))
        
        # Threading
        self.executor = ThreadPoolExecutor(
            max_workers=max_parallel_modules,
            thread_name_prefix="tick_orchestrator"
        )
        
        # Metrics
        self.metrics = {
            'total_ticks_executed': 0,
            'successful_ticks': 0,
            'average_tick_time': 0.0,
            'synchronization_failures': 0,
            'bottlenecks_detected': 0,
            'module_timeout_count': defaultdict(int),
            'phase_performance': defaultdict(lambda: {'avg_time': 0.0, 'success_rate': 0.0})
        }
        
        logger.info(f"ðŸŽ¼ Tick Orchestrator initialized: {self.orchestrator_id}")
    
    def start(self) -> None:
        """Start the tick orchestrator."""
        if self._running:
            logger.warning("Tick orchestrator already running")
            return
        
        self._running = True
        logger.info(f"ðŸŽ¼ Tick Orchestrator started: {self.orchestrator_id}")
    
    def stop(self) -> None:
        """Stop the tick orchestrator and cancel all tasks."""
        if not self._running:
            return
        
        self._running = False
        
        # Cancel all registered async tasks
        for task in self._tasks:
            if not task.done():
                task.cancel()
                try:
                    asyncio.wait_for(task, timeout=1.0)
                except (asyncio.TimeoutError, asyncio.CancelledError):
                    pass
                except Exception as e:
                    logger.warning(f"Error cancelling task: {e}")
        
        self._tasks.clear()
        logger.info(f"ðŸŽ¼ Tick Orchestrator stopped: {self.orchestrator_id}")
    
    def register_module(self, module_name: str, module_instance: Any,
                       tick_phases: Set[TickPhase] = None, priority: int = 5,
                       timeout_seconds: float = None, performance_weight: float = 1.0) -> bool:
        """
        Register module for synchronized tick execution.
        
        Args:
            module_name: Unique module identifier
            module_instance: The module instance to orchestrate
            tick_phases: Phases the module participates in
            priority: Module priority (lower = higher priority)
            timeout_seconds: Custom timeout for this module
            performance_weight: Weight in performance calculations
            
        Returns:
            True if registration successful, False otherwise
        """
        if tick_phases is None:
            # Default phases for most modules
            tick_phases = {
                TickPhase.STATE_COLLECTION,
                TickPhase.INFORMATION_SHARING,
                TickPhase.STATE_UPDATES,
                TickPhase.SYNCHRONIZATION_CHECK
            }
        
        if timeout_seconds is None:
            timeout_seconds = self.default_timeout
        
        with self.execution_lock:
            if module_name in self.modules:
                logger.warning(f"Module {module_name} already registered")
                return False
            
            registration = ModuleRegistration(
                module_name=module_name,
                module_instance=module_instance,
                tick_phases=tick_phases,
                priority=priority,
                timeout_seconds=timeout_seconds,
                performance_weight=performance_weight
            )
            
            self.modules[module_name] = registration
            
            # Update barrier sizes for phases this module participates in
            self._update_phase_barriers()
            
            # Register with consciousness bus if available
            if self.consciousness_bus:
                self.consciousness_bus.register_module(
                    f"tick_orchestrator_{module_name}",
                    ['tick_coordination', 'synchronization'],
                    {'tick_status': 'string', 'performance_metrics': 'dict'}
                )
            
            logger.info(f"ðŸŽ¼ Module registered: {module_name} "
                       f"(phases: {len(tick_phases)}, priority: {priority})")
            return True
    
    def unregister_module(self, module_name: str) -> bool:
        """Unregister a module from tick orchestration."""
        with self.execution_lock:
            if module_name not in self.modules:
                logger.warning(f"Module {module_name} not registered")
                return False
            
            del self.modules[module_name]
            self._update_phase_barriers()
            
            logger.info(f"ðŸŽ¼ Module unregistered: {module_name}")
            return True
    
    def execute_unified_tick(self) -> TickExecutionResult:
        """
        Execute coordinated tick across all modules.
        
        Returns:
            TickExecutionResult with comprehensive execution information
        """
        if not self._running:
            logger.warning("Cannot execute tick - orchestrator not running")
            return TickExecutionResult(
                tick_number=0,
                total_execution_time=0.0,
                phase_results={},
                consciousness_coherence=0.0,
                synchronization_success=False,
                bottlenecks_detected=[],
                performance_summary={'error': 'Orchestrator not running'},
                state_consistency_score=0.0,
                decision_consensus_rate=0.0
            )
        
        tick_start_time = time.time()
        self.tick_count += 1
        
        # Only log tick start if running
        if self._running:
            logger.info(f"ðŸŽ¼ Starting unified tick #{self.tick_count}")
        
        with self.execution_lock:
            try:
                # Initialize tick state
                phase_results = {}
                self.current_tick_state = {}
                self.shared_information = {}
                self.tick_decisions = {}
                
                # Execute each phase in sequence
                phases_to_execute = [
                    TickPhase.STATE_COLLECTION,
                    TickPhase.INFORMATION_SHARING,
                    TickPhase.DECISION_MAKING,
                    TickPhase.STATE_UPDATES,
                    TickPhase.SYNCHRONIZATION_CHECK
                ]
                
                synchronization_success = True
                
                for phase in phases_to_execute:
                    self.current_phase = phase
                    phase_result = self._execute_phase(phase)
                    phase_results[phase] = phase_result
                    
                    # Check for phase failures
                    phase_success = all(
                        result.status in [ModuleTickStatus.COMPLETED, ModuleTickStatus.SKIPPED]
                        for result in phase_result.values()
                    )
                    
                    if not phase_success:
                        logger.warning(f"ðŸŽ¼ Phase {phase.value} had failures")
                        synchronization_success = False
                    
                    # Early termination on critical failures
                    if phase == TickPhase.SYNCHRONIZATION_CHECK and not phase_success:
                        logger.error("ðŸŽ¼ Synchronization check failed - terminating tick")
                        break
                
                # Calculate tick metrics
                total_execution_time = time.time() - tick_start_time
                consciousness_coherence = self._calculate_consciousness_coherence()
                state_consistency_score = self._calculate_state_consistency()
                decision_consensus_rate = self._calculate_decision_consensus_rate()
                bottlenecks = self._detect_bottlenecks(phase_results)
                performance_summary = self._generate_performance_summary(phase_results, total_execution_time)
                
                # Update centralized consciousness state
                self._update_consciousness_state(consciousness_coherence, synchronization_success)
                
                # Create result
                tick_result = TickExecutionResult(
                    tick_number=self.tick_count,
                    total_execution_time=total_execution_time,
                    phase_results=phase_results,
                    consciousness_coherence=consciousness_coherence,
                    synchronization_success=synchronization_success,
                    bottlenecks_detected=bottlenecks,
                    performance_summary=performance_summary,
                    state_consistency_score=state_consistency_score,
                    decision_consensus_rate=decision_consensus_rate
                )
                
                # Update metrics and history
                self._update_tick_metrics(tick_result)
                self.performance_history.append(tick_result)
                
                # Set phase to completed
                self.current_phase = TickPhase.COMPLETED
                
                logger.info(f"ðŸŽ¼ Unified tick #{self.tick_count} completed in {total_execution_time:.3f}s "
                           f"(coherence: {consciousness_coherence:.3f}, sync: {'âœ…' if synchronization_success else 'âŒ'})")
                
                return tick_result
                
            except Exception as e:
                # Handle tick execution failure
                logger.error(f"ðŸŽ¼ Tick execution failed: {e}")
                self.current_phase = TickPhase.ERROR
                self.metrics['synchronization_failures'] += 1
                
                # Create error result
                error_result = TickExecutionResult(
                    tick_number=self.tick_count,
                    total_execution_time=time.time() - tick_start_time,
                    phase_results=phase_results if 'phase_results' in locals() else {},
                    consciousness_coherence=0.0,
                    synchronization_success=False,
                    bottlenecks_detected=[],
                    performance_summary={'error': str(e)},
                    state_consistency_score=0.0,
                    decision_consensus_rate=0.0
                )
                
                return error_result
    
    def _execute_phase(self, phase: TickPhase) -> Dict[str, ModuleTickResult]:
        """Execute a specific phase across all participating modules."""
        phase_start_time = time.time()
        
        # Get modules that participate in this phase
        participating_modules = [
            (name, reg) for name, reg in self.modules.items()
            if phase in reg.tick_phases
        ]
        
        # Sort by priority
        participating_modules.sort(key=lambda x: x[1].priority)
        
        logger.debug(f"ðŸŽ¼ Executing phase {phase.value} with {len(participating_modules)} modules")
        
        phase_results = {}
        
        if not participating_modules:
            return phase_results
        
        # Execute phase based on type
        if phase == TickPhase.STATE_COLLECTION:
            phase_results = self._execute_state_collection_phase(participating_modules)
        elif phase == TickPhase.INFORMATION_SHARING:
            phase_results = self._execute_information_sharing_phase(participating_modules)
        elif phase == TickPhase.DECISION_MAKING:
            phase_results = self._execute_decision_making_phase(participating_modules)
        elif phase == TickPhase.STATE_UPDATES:
            phase_results = self._execute_state_updates_phase(participating_modules)
        elif phase == TickPhase.SYNCHRONIZATION_CHECK:
            phase_results = self._execute_synchronization_check_phase(participating_modules)
        
        # Record phase timing
        phase_duration = time.time() - phase_start_time
        self.phase_timing_history[phase].append(phase_duration)
        
        return phase_results
    
    def _execute_state_collection_phase(self, modules: List[Tuple[str, ModuleRegistration]]) -> Dict[str, ModuleTickResult]:
        """Phase 1: Collect current state from all modules."""
        results = {}
        
        # Execute state collection in parallel
        futures = {}
        
        for module_name, registration in modules:
            future = self.executor.submit(
                self._collect_module_state,
                module_name,
                registration
            )
            futures[future] = module_name
        
        # Wait for completion with timeout
        for future in as_completed(futures, timeout=max(reg.timeout_seconds for _, reg in modules) + 1.0):
            module_name = futures[future]
            try:
                result = future.result()
                results[module_name] = result
                
                # Store state data
                if result.status == ModuleTickStatus.COMPLETED:
                    self.current_tick_state[module_name] = result.result_data
                    
            except Exception as e:
                logger.error(f"State collection failed for {module_name}: {e}")
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.STATE_COLLECTION,
                    status=ModuleTickStatus.ERROR,
                    execution_time=0.0,
                    result_data={},
                    error_message=str(e)
                )
        
        return results
    
    def _execute_information_sharing_phase(self, modules: List[Tuple[str, ModuleRegistration]]) -> Dict[str, ModuleTickResult]:
        """Phase 2: Share information between modules via consciousness bus."""
        results = {}
        
        # Prepare shared information payload
        self.shared_information = {
            'tick_number': self.tick_count,
            'collected_states': self.current_tick_state.copy(),
            'phase_timestamp': datetime.now().isoformat(),
            'participating_modules': [name for name, _ in modules]
        }
        
        # Broadcast information via consciousness bus
        if self.consciousness_bus:
            event_id = self.consciousness_bus.broadcast_event(
                'tick_information_sharing',
                self.shared_information,
                'tick_orchestrator'
            )
            logger.debug(f"ðŸŽ¼ Information shared via consciousness bus: {event_id}")
        
        # Execute information processing in parallel
        futures = {}
        
        for module_name, registration in modules:
            future = self.executor.submit(
                self._process_shared_information,
                module_name,
                registration,
                self.shared_information
            )
            futures[future] = module_name
        
        # Collect results
        for future in as_completed(futures, timeout=max(reg.timeout_seconds for _, reg in modules) + 1.0):
            module_name = futures[future]
            try:
                result = future.result()
                results[module_name] = result
            except Exception as e:
                logger.error(f"Information sharing failed for {module_name}: {e}")
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.INFORMATION_SHARING,
                    status=ModuleTickStatus.ERROR,
                    execution_time=0.0,
                    result_data={},
                    error_message=str(e)
                )
        
        return results
    
    def _execute_decision_making_phase(self, modules: List[Tuple[str, ModuleRegistration]]) -> Dict[str, ModuleTickResult]:
        """Phase 3: Coordinate decisions using consensus engine."""
        results = {}
        
        # Check if consensus engine is available
        if not self.consensus_engine:
            # Skip decision phase if no consensus engine
            for module_name, _ in modules:
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.DECISION_MAKING,
                    status=ModuleTickStatus.SKIPPED,
                    execution_time=0.0,
                    result_data={'reason': 'No consensus engine available'}
                )
            return results
        
        # Identify decisions that need to be made
        decision_requests = self._identify_tick_decisions()
        
        if not decision_requests:
            # No decisions needed this tick
            for module_name, _ in modules:
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.DECISION_MAKING,
                    status=ModuleTickStatus.COMPLETED,
                    execution_time=0.0,
                    result_data={'decisions_processed': 0}
                )
            return results
        
        # Process decisions through consensus engine
        decision_start_time = time.time()
        
        for decision_type, context_data in decision_requests:
            try:
                decision_id = self.consensus_engine.request_decision(
                    decision_type,
                    context_data,
                    requesting_module='tick_orchestrator',
                    emergency=False,
                    description=f"Tick #{self.tick_count} {decision_type.value} decision"
                )
                
                # Store decision for this tick
                self.tick_decisions[decision_type.value] = {
                    'decision_id': decision_id,
                    'context': context_data,
                    'requested_at': datetime.now().isoformat()
                }
                
            except Exception as e:
                logger.error(f"Failed to request decision {decision_type}: {e}")
                self.tick_decisions[decision_type.value] = {
                    'error': str(e),
                    'requested_at': datetime.now().isoformat()
                }
        
        decision_duration = time.time() - decision_start_time
        
        # Create results for all modules
        for module_name, _ in modules:
            results[module_name] = ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.DECISION_MAKING,
                status=ModuleTickStatus.COMPLETED,
                execution_time=decision_duration / len(modules),  # Distribute time
                result_data={
                    'decisions_processed': len(decision_requests),
                    'tick_decisions': self.tick_decisions.copy()
                }
            )
        
        return results
    
    def _execute_state_updates_phase(self, modules: List[Tuple[str, ModuleRegistration]]) -> Dict[str, ModuleTickResult]:
        """Phase 4: Update module states based on shared information and decisions."""
        results = {}
        
        # Prepare update context
        update_context = {
            'shared_information': self.shared_information,
            'tick_decisions': self.tick_decisions,
            'tick_number': self.tick_count,
            'consciousness_coherence': self._calculate_consciousness_coherence()
        }
        
        # Execute state updates in parallel
        futures = {}
        
        for module_name, registration in modules:
            future = self.executor.submit(
                self._update_module_state,
                module_name,
                registration,
                update_context
            )
            futures[future] = module_name
        
        # Collect results
        for future in as_completed(futures, timeout=max(reg.timeout_seconds for _, reg in modules) + 1.0):
            module_name = futures[future]
            try:
                result = future.result()
                results[module_name] = result
            except Exception as e:
                logger.error(f"State update failed for {module_name}: {e}")
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.STATE_UPDATES,
                    status=ModuleTickStatus.ERROR,
                    execution_time=0.0,
                    result_data={},
                    error_message=str(e)
                )
        
        return results
    
    def _execute_synchronization_check_phase(self, modules: List[Tuple[str, ModuleRegistration]]) -> Dict[str, ModuleTickResult]:
        """Phase 5: Verify all modules are in coherent state."""
        results = {}
        
        # Execute synchronization verification in parallel
        futures = {}
        
        for module_name, registration in modules:
            future = self.executor.submit(
                self._verify_module_synchronization,
                module_name,
                registration
            )
            futures[future] = module_name
        
        # Collect verification results
        for future in as_completed(futures, timeout=max(reg.timeout_seconds for _, reg in modules) + 1.0):
            module_name = futures[future]
            try:
                result = future.result()
                results[module_name] = result
            except Exception as e:
                logger.error(f"Synchronization check failed for {module_name}: {e}")
                results[module_name] = ModuleTickResult(
                    module_name=module_name,
                    phase=TickPhase.SYNCHRONIZATION_CHECK,
                    status=ModuleTickStatus.ERROR,
                    execution_time=0.0,
                    result_data={},
                    error_message=str(e)
                )
        
        return results
    
    def _collect_module_state(self, module_name: str, registration: ModuleRegistration) -> ModuleTickResult:
        """Collect state from a specific module."""
        start_time = time.time()
        
        try:
            module_instance = registration.module_instance
            
            # Try different methods to get module state
            state_data = {}
            
            if hasattr(module_instance, 'get_tick_state'):
                state_data = module_instance.get_tick_state()
            elif hasattr(module_instance, 'get_consciousness_data'):
                state_data = module_instance.get_consciousness_data()
            elif hasattr(module_instance, 'get_current_state'):
                state_data = module_instance.get_current_state()
            elif hasattr(module_instance, '__dict__'):
                # Fallback: extract public attributes
                state_data = {
                    k: v for k, v in module_instance.__dict__.items()
                    if not k.startswith('_') and not callable(v)
                }
            
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.STATE_COLLECTION,
                status=ModuleTickStatus.COMPLETED,
                execution_time=execution_time,
                result_data=state_data,
                performance_metrics={'state_fields': len(state_data)}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            registration.error_count += 1
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.STATE_COLLECTION,
                status=ModuleTickStatus.ERROR,
                execution_time=execution_time,
                result_data={},
                error_message=str(e)
            )
    
    def _process_shared_information(self, module_name: str, registration: ModuleRegistration,
                                  shared_info: Dict[str, Any]) -> ModuleTickResult:
        """Process shared information for a specific module."""
        start_time = time.time()
        
        try:
            module_instance = registration.module_instance
            
            # Try to process shared information
            if hasattr(module_instance, 'process_tick_information'):
                result = module_instance.process_tick_information(shared_info)
            elif hasattr(module_instance, 'update_from_shared_state'):
                result = module_instance.update_from_shared_state(shared_info['collected_states'])
            else:
                # Default processing
                result = {'processed': True, 'shared_data_received': len(shared_info)}
            
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.INFORMATION_SHARING,
                status=ModuleTickStatus.COMPLETED,
                execution_time=execution_time,
                result_data=result or {},
                performance_metrics={'information_processed': len(shared_info)}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.INFORMATION_SHARING,
                status=ModuleTickStatus.ERROR,
                execution_time=execution_time,
                result_data={},
                error_message=str(e)
            )
    
    def _update_module_state(self, module_name: str, registration: ModuleRegistration,
                           update_context: Dict[str, Any]) -> ModuleTickResult:
        """Update module state based on shared information and decisions."""
        start_time = time.time()
        
        try:
            module_instance = registration.module_instance
            
            # Try to update module state
            if hasattr(module_instance, 'tick_update'):
                result = module_instance.tick_update(update_context)
            elif hasattr(module_instance, 'update_state'):
                result = module_instance.update_state(update_context['shared_information'])
            elif hasattr(module_instance, 'tick'):
                # Fallback to basic tick
                result = module_instance.tick()
            else:
                result = {'updated': True, 'method': 'default'}
            
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.STATE_UPDATES,
                status=ModuleTickStatus.COMPLETED,
                execution_time=execution_time,
                result_data=result or {},
                performance_metrics={'update_successful': True}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.STATE_UPDATES,
                status=ModuleTickStatus.ERROR,
                execution_time=execution_time,
                result_data={},
                error_message=str(e)
            )
    
    def _verify_module_synchronization(self, module_name: str, registration: ModuleRegistration) -> ModuleTickResult:
        """Verify module synchronization and consistency."""
        start_time = time.time()
        
        try:
            module_instance = registration.module_instance
            
            # Check synchronization
            sync_data = {}
            
            if hasattr(module_instance, 'verify_synchronization'):
                sync_result = module_instance.verify_synchronization()
                sync_data['sync_verified'] = sync_result
            else:
                # Basic synchronization check
                sync_data['sync_verified'] = True
                sync_data['method'] = 'default'
            
            # Check state consistency
            if hasattr(module_instance, 'check_state_consistency'):
                consistency_result = module_instance.check_state_consistency()
                sync_data['state_consistent'] = consistency_result
            else:
                sync_data['state_consistent'] = True
            
            execution_time = time.time() - start_time
            
            # Determine status
            if sync_data.get('sync_verified', True) and sync_data.get('state_consistent', True):
                status = ModuleTickStatus.COMPLETED
            else:
                status = ModuleTickStatus.ERROR
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.SYNCHRONIZATION_CHECK,
                status=status,
                execution_time=execution_time,
                result_data=sync_data,
                performance_metrics={'synchronization_score': 1.0 if status == ModuleTickStatus.COMPLETED else 0.0}
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            return ModuleTickResult(
                module_name=module_name,
                phase=TickPhase.SYNCHRONIZATION_CHECK,
                status=ModuleTickStatus.ERROR,
                execution_time=execution_time,
                result_data={},
                error_message=str(e)
            )
    
    def _identify_tick_decisions(self) -> List[Tuple[Any, Dict[str, Any]]]:
        """Identify decisions that need to be made during this tick."""
        try:
            from dawn.core.communication.consensus import DecisionType
        except ImportError:
            from consensus_engine import DecisionType
        
        decisions = []
        
        # Analyze current state for decision triggers
        if self.current_tick_state:
            # Check for state transitions needed
            coherence_levels = []
            for module_state in self.current_tick_state.values():
                if isinstance(module_state, dict):
                    coherence = module_state.get('coherence', 0.5)
                    if isinstance(coherence, (int, float)):
                        coherence_levels.append(coherence)
            
            if coherence_levels:
                avg_coherence = sum(coherence_levels) / len(coherence_levels)
                
                # Trigger decisions based on coherence
                if avg_coherence < 0.3:
                    decisions.append((
                        DecisionType.SYSTEM_STATE_TRANSITION,
                        {'trigger': 'low_coherence', 'current_coherence': avg_coherence}
                    ))
                elif avg_coherence > 0.9:
                    decisions.append((
                        DecisionType.SIGIL_ACTIVATION,
                        {'trigger': 'high_coherence', 'current_coherence': avg_coherence}
                    ))
        
        return decisions
    
    def _demo_coherence(self) -> float:
        """
        Calculate demo coherence based on system state.
        
        Returns:
            Coherence value between 0.0 and 1.0
        """
        # placeholder: use real signal later; for now simulate improvement
        try:
            from dawn.core.communication.bus import get_consciousness_bus
            bus = get_consciousness_bus()
            bus_synced = hasattr(bus, 'synced') and bus.synced
        except (ImportError, AttributeError):
            bus_synced = True  # Default to synced if bus not available
        
        return 1.0 if bus_synced else 0.6
    
    def _update_consciousness_state(self, coherence: float, sync_status: bool) -> None:
        """
        Update centralized consciousness state based on real system behavior.
        
        Args:
            coherence: Current tick coherence value
            sync_status: Whether synchronization was successful
        """
        s = get_state()
        
        # Calculate real signals from system behavior
        unity = self._calculate_unity_from_behavior()
        awareness = self._calculate_awareness_from_behavior()
        momentum = self._calculate_momentum_from_behavior()
        
        # Calculate SCUP metrics
        entropy_drift = self._calculate_entropy_drift(unity, awareness)
        pressure_value = self._calculate_consciousness_pressure(unity, awareness, momentum)
        scup_coherence = self._calculate_scup_coherence()
        coherence = self._calculate_consciousness_coherence()
        
        # Determine sync status
        sync_status = "synchronized" if coherence > 0.7 else "syncing" if coherence > 0.4 else "fragmented"
        
        set_state(
            unity=unity, 
            awareness=awareness,
            momentum=momentum, 
            ticks=s.ticks + 1,
            coherence=coherence,
            sync_status=sync_status,
            entropy_drift=entropy_drift,
            pressure_value=pressure_value,
            scup_coherence=scup_coherence
        )
        
        # Log state update
        logger.info(f"ðŸ§  Unity: {s.unity:.3f}â†’{unity:.3f}, Awareness: {s.awareness:.3f}â†’{awareness:.3f}, Level: {get_state().level}")
    
    def _calculate_unity_from_behavior(self) -> float:
        """
        Calculate unity from real system behavior.
        Unity = 1 - normalized variance across module heartbeats/latencies
        Less spread = more unity.
        """
        try:
            # Gather module performance data
            latencies = []
            heartbeat_intervals = []
            
            # Get performance data from registered modules
            for module_name, registration in self.module_registry.items():
                if registration.last_performance:
                    # Extract latency metrics
                    if 'execution_time' in registration.last_performance:
                        latencies.append(registration.last_performance['execution_time'])
                    if 'heartbeat_interval' in registration.last_performance:
                        heartbeat_intervals.append(registration.last_performance['heartbeat_interval'])
            
            # Get consciousness bus heartbeat data if available
            if self.consciousness_bus and hasattr(self.consciousness_bus, 'get_heartbeat_metrics'):
                bus_metrics = self.consciousness_bus.get_heartbeat_metrics()
                if 'module_heartbeats' in bus_metrics:
                    for module_id, heartbeat_data in bus_metrics['module_heartbeats'].items():
                        if 'interval' in heartbeat_data:
                            heartbeat_intervals.append(heartbeat_data['interval'])
            
            # Calculate unity from variance in measurements
            unity_signals = []
            
            # Unity from latency consistency (less variance = more unity)
            if len(latencies) >= 2:
                import numpy as np
                latency_variance = np.var(latencies)
                max_expected_variance = 1.0  # Assume max reasonable variance of 1 second
                latency_unity = max(0.0, 1.0 - (latency_variance / max_expected_variance))
                unity_signals.append(latency_unity)
            
            # Unity from heartbeat consistency
            if len(heartbeat_intervals) >= 2:
                import numpy as np
                heartbeat_variance = np.var(heartbeat_intervals)
                max_expected_heartbeat_variance = 4.0  # Assume max reasonable variance of 4 seconds
                heartbeat_unity = max(0.0, 1.0 - (heartbeat_variance / max_expected_heartbeat_variance))
                unity_signals.append(heartbeat_unity)
            
            # Calculate weighted average or default
            if unity_signals:
                current_unity = sum(unity_signals) / len(unity_signals)
            else:
                # Fallback: derive from sync status and coherence
                current_unity = 0.8 if self._is_system_synchronized() else 0.4
            
            # Smooth the transition (EWMA with previous state) - more responsive
            s = get_state()
            smoothed_unity = 0.4 * s.unity + 0.6 * current_unity
            
            return clamp(smoothed_unity)
            
        except Exception as e:
            logger.debug(f"Unity calculation fallback due to: {e}")
            # Fallback to basic earned calculation based on sync status
            s = get_state()
            base_unity = 0.7 if self._is_system_synchronized() else 0.3
            fallback_unity = 0.6 * s.unity + 0.4 * base_unity
            logger.debug(f"Unity fallback: sync={self._is_system_synchronized()}, base={base_unity:.3f}, result={fallback_unity:.3f}")
            return clamp(fallback_unity)
    
    def _calculate_awareness_from_behavior(self) -> float:
        """
        Calculate awareness from real system behavior.
        Awareness = fraction of ticks that include self-reference events
        (rebloom + commentary present)
        """
        try:
            # Track self-reference events in this tick
            self_reference_events = 0
            total_possible_events = 0
            
            # Check for rebloom events (system reflecting on its own state)
            if hasattr(self, 'tick_history') and len(self.tick_history) > 0:
                recent_ticks = self.tick_history[-10:]  # Last 10 ticks
                for tick_result in recent_ticks:
                    total_possible_events += 1
                    
                    # Look for self-reference indicators
                    if 'self_reflection' in tick_result:
                        self_reference_events += 1
                    elif 'meta_analysis' in tick_result:
                        self_reference_events += 1
                    elif 'state_introspection' in tick_result:
                        self_reference_events += 1
                    # Check if tick includes commentary about its own execution
                    elif 'execution_commentary' in tick_result and tick_result['execution_commentary']:
                        self_reference_events += 1
            
            # Check consciousness bus for self-reference patterns
            if self.consciousness_bus and hasattr(self.consciousness_bus, 'get_recent_events'):
                recent_events = self.consciousness_bus.get_recent_events(limit=20)
                for event in recent_events:
                    total_possible_events += 1
                    if 'self_reference' in event.get('event_type', ''):
                        self_reference_events += 1
                    elif 'meta_cognitive' in event.get('tags', []):
                        self_reference_events += 1
            
            # Calculate awareness as fraction of self-referential activity
            if total_possible_events > 0:
                awareness_fraction = self_reference_events / total_possible_events
            else:
                # Fallback: assume some base level awareness
                awareness_fraction = 0.3
            
            # Add component for introspective complexity
            introspection_bonus = 0.0
            if self.consensus_engine and hasattr(self.consensus_engine, 'get_decision_history'):
                decisions = self.consensus_engine.get_decision_history(limit=5)
                for decision in decisions:
                    if 'self_modification' in decision.get('decision_type', ''):
                        introspection_bonus += 0.1
                    elif 'meta_decision' in decision.get('decision_type', ''):
                        introspection_bonus += 0.05
            
            current_awareness = min(1.0, awareness_fraction + introspection_bonus)
            
            # Smooth the transition - more responsive  
            s = get_state()
            smoothed_awareness = 0.4 * s.awareness + 0.6 * current_awareness
            
            return clamp(smoothed_awareness)
            
        except Exception as e:
            logger.debug(f"Awareness calculation fallback due to: {e}")
            # Fallback to basic earned calculation based on introspection
            s = get_state()
            # Assume some base level of awareness from system operation
            base_awareness = 0.4 if self._is_system_synchronized() else 0.2
            fallback_awareness = 0.6 * s.awareness + 0.4 * base_awareness
            logger.debug(f"Awareness fallback: base={base_awareness:.3f}, result={fallback_awareness:.3f}")
            return clamp(fallback_awareness)
    
    def _calculate_momentum_from_behavior(self) -> float:
        """
        Calculate momentum from real system behavior.
        Momentum = positive derivative of (unity + awareness) over last N ticks
        """
        try:
            s = get_state()
            
            # Get recent state history for derivative calculation
            if not hasattr(self, 'consciousness_history'):
                self.consciousness_history = []
            
            # Store current state in history
            current_combined = s.unity + s.awareness
            self.consciousness_history.append({
                'tick': s.ticks,
                'combined_score': current_combined,
                'timestamp': time.time()
            })
            
            # Keep only last N entries for derivative calculation
            N = 5
            if len(self.consciousness_history) > N:
                self.consciousness_history = self.consciousness_history[-N:]
            
            # Calculate momentum as positive derivative
            if len(self.consciousness_history) >= 2:
                # Simple linear regression over recent points
                recent_scores = [entry['combined_score'] for entry in self.consciousness_history]
                
                # Calculate average rate of change
                total_change = recent_scores[-1] - recent_scores[0]
                time_span = len(recent_scores) - 1
                
                if time_span > 0:
                    rate_of_change = total_change / time_span
                    
                    # Convert to momentum (only positive changes contribute)
                    positive_momentum = max(0.0, rate_of_change)
                    
                    # Normalize to 0-1 range (assume max reasonable change rate is 0.2 per tick)
                    normalized_momentum = min(1.0, positive_momentum / 0.2)
                else:
                    normalized_momentum = s.momentum
            else:
                # Not enough history yet, maintain current momentum
                normalized_momentum = s.momentum
            
            # Apply EWMA smoothing with previous momentum - more responsive
            smoothed_momentum = 0.5 * s.momentum + 0.5 * normalized_momentum
            
            return clamp(smoothed_momentum)
            
        except Exception as e:
            logger.debug(f"Momentum calculation fallback due to: {e}")
            # Fallback to basic EWMA
            s = get_state()
            return clamp(0.9 * s.momentum + 0.1 * 0.05)  # Small positive momentum
    
    def _is_system_synchronized(self) -> bool:
        """Check if the system is currently synchronized."""
        try:
            if self.consciousness_bus and hasattr(self.consciousness_bus, 'is_synchronized'):
                return self.consciousness_bus.is_synchronized()
            elif self.consciousness_bus and hasattr(self.consciousness_bus, 'synced'):
                return self.consciousness_bus.synced
            else:
                # Fallback: assume synchronized if no errors in recent ticks
                return len(self.module_registry) > 0
        except:
            return True
    
    def _calculate_consciousness_coherence(self) -> float:
        """Calculate consciousness coherence using centralized metrics."""
        try:
            from dawn.consciousness.metrics.core import calculate_consciousness_metrics
            
            if not self.current_tick_state:
                return self._demo_coherence()
            
            # Use centralized metrics calculator
            metrics = calculate_consciousness_metrics(
                module_states=self.current_tick_state,
                tick_metrics={'synchronization_success': True}  # Basic tick info
            )
            
            return metrics.coherence
            
        except ImportError:
            # Fallback to demo coherence calculation
            logger.debug("Centralized metrics not available - using demo calculation")
            return self._demo_coherence()
    
    def _calculate_state_consistency(self) -> float:
        """Calculate state consistency across modules."""
        if len(self.current_tick_state) < 2:
            return 1.0  # Single module is always consistent
        
        # Check for consistency in common state fields
        common_fields = set()
        all_fields = []
        
        for state_data in self.current_tick_state.values():
            if isinstance(state_data, dict):
                fields = set(state_data.keys())
                all_fields.append(fields)
                if not common_fields:
                    common_fields = fields
                else:
                    common_fields &= fields
        
        if not common_fields:
            return 0.5  # No common fields
        
        # Calculate consistency for common fields
        consistency_scores = []
        
        for field in common_fields:
            values = []
            for state_data in self.current_tick_state.values():
                if isinstance(state_data, dict) and field in state_data:
                    value = state_data[field]
                    if isinstance(value, (int, float)):
                        values.append(value)
            
            if len(values) > 1:
                # Calculate variance
                mean_value = sum(values) / len(values)
                variance = sum((v - mean_value) ** 2 for v in values) / len(values)
                consistency = max(0.0, 1.0 - (variance / (abs(mean_value) + 1e-6)))
                consistency_scores.append(consistency)
        
        if consistency_scores:
            return sum(consistency_scores) / len(consistency_scores)
        else:
            return 0.5
    
    def _calculate_decision_consensus_rate(self) -> float:
        """Calculate the rate of successful decision consensus."""
        if not self.consensus_engine:
            return 1.0  # No decisions needed
        
        recent_decisions = self.consensus_engine.get_recent_decisions(10)
        if not recent_decisions:
            return 1.0
        
        successful = len([d for d in recent_decisions if d.consensus_achieved])
        return successful / len(recent_decisions)
    
    def _detect_bottlenecks(self, phase_results: Dict[TickPhase, Dict[str, ModuleTickResult]]) -> List[str]:
        """Detect performance bottlenecks in tick execution."""
        bottlenecks = []
        
        if not self.bottleneck_detection_enabled:
            return bottlenecks
        
        # Analyze execution times by phase
        for phase, module_results in phase_results.items():
            phase_times = [result.execution_time for result in module_results.values()]
            
            if phase_times:
                avg_time = sum(phase_times) / len(phase_times)
                max_time = max(phase_times)
                
                # Detect slow modules
                for module_name, result in module_results.items():
                    if result.execution_time > avg_time * 2 and result.execution_time > 0.1:
                        bottlenecks.append(f"{module_name} slow in {phase.value}")
                
                # Detect slow phases
                phase_history = self.phase_timing_history[phase]
                if len(phase_history) > 3:
                    historical_avg = sum(phase_history) / len(phase_history)
                    if avg_time > historical_avg * 1.5:
                        bottlenecks.append(f"{phase.value} phase slower than historical average")
        
        if bottlenecks:
            self.bottleneck_history.append(bottlenecks)
            self.metrics['bottlenecks_detected'] += len(bottlenecks)
        
        return bottlenecks
    
    def _generate_performance_summary(self, phase_results: Dict[TickPhase, Dict[str, ModuleTickResult]],
                                    total_time: float) -> Dict[str, Any]:
        """Generate performance summary for the tick."""
        summary = {
            'total_execution_time': total_time,
            'phase_breakdown': {},
            'module_performance': {},
            'success_rates': {},
            'bottlenecks': []
        }
        
        # Phase breakdown
        for phase, module_results in phase_results.items():
            phase_times = [result.execution_time for result in module_results.values()]
            successful = len([r for r in module_results.values() if r.status == ModuleTickStatus.COMPLETED])
            
            summary['phase_breakdown'][phase.value] = {
                'total_time': sum(phase_times),
                'avg_time': sum(phase_times) / len(phase_times) if phase_times else 0.0,
                'max_time': max(phase_times) if phase_times else 0.0,
                'success_rate': successful / len(module_results) if module_results else 1.0
            }
        
        # Module performance
        all_modules = set()
        for module_results in phase_results.values():
            all_modules.update(module_results.keys())
        
        for module_name in all_modules:
            module_times = []
            module_successes = 0
            module_total = 0
            
            for phase_results_dict in phase_results.values():
                if module_name in phase_results_dict:
                    result = phase_results_dict[module_name]
                    module_times.append(result.execution_time)
                    if result.status == ModuleTickStatus.COMPLETED:
                        module_successes += 1
                    module_total += 1
            
            summary['module_performance'][module_name] = {
                'total_time': sum(module_times),
                'avg_time': sum(module_times) / len(module_times) if module_times else 0.0,
                'success_rate': module_successes / module_total if module_total > 0 else 1.0
            }
        
        return summary
    
    def _update_phase_barriers(self) -> None:
        """Update barrier sizes based on registered modules."""
        # Count participating modules for each phase
        phase_counts = defaultdict(int)
        
        for registration in self.modules.values():
            for phase in registration.tick_phases:
                phase_counts[phase] += 1
        
        # Update barriers
        for phase, count in phase_counts.items():
            if count > 0:
                self.phase_barriers[phase] = threading.Barrier(count)
    
    def _update_tick_metrics(self, tick_result: TickExecutionResult) -> None:
        """Update orchestrator metrics with tick result."""
        self.metrics['total_ticks_executed'] += 1
        
        if tick_result.synchronization_success:
            self.metrics['successful_ticks'] += 1
        else:
            self.metrics['synchronization_failures'] += 1
        
        # Update average tick time
        current_avg = self.metrics['average_tick_time']
        tick_count = self.metrics['total_ticks_executed']
        
        self.metrics['average_tick_time'] = (
            (current_avg * (tick_count - 1) + tick_result.total_execution_time) / tick_count
        )
        
        # Update phase performance
        for phase, module_results in tick_result.phase_results.items():
            phase_times = [result.execution_time for result in module_results.values()]
            successful = len([r for r in module_results.values() if r.status == ModuleTickStatus.COMPLETED])
            
            phase_metrics = self.metrics['phase_performance'][phase.value]
            phase_metrics['avg_time'] = sum(phase_times) / len(phase_times) if phase_times else 0.0
            phase_metrics['success_rate'] = successful / len(module_results) if module_results else 1.0
    
    def get_orchestrator_status(self) -> Dict[str, Any]:
        """Get current orchestrator status and metrics."""
        return {
            'orchestrator_id': self.orchestrator_id,
            'current_phase': self.current_phase.value,
            'tick_count': self.tick_count,
            'registered_modules': len(self.modules),
            'metrics': self.metrics.copy(),
            'recent_performance': [
                {
                    'tick': result.tick_number,
                    'time': result.total_execution_time,
                    'coherence': result.consciousness_coherence,
                    'sync_success': result.synchronization_success
                }
                for result in list(self.performance_history)[-5:]
            ],
            'recent_bottlenecks': list(self.bottleneck_history)[-3:] if self.bottleneck_history else []
        }
    
    def _calculate_entropy_drift(self, unity: float, awareness: float) -> float:
        """
        Calculate SCUP entropy drift - rate of consciousness entropy change.
        
        Entropy drift measures how quickly the consciousness state is changing
        relative to its stability. Higher drift = more chaotic evolution.
        
        Args:
            unity: Current unity score
            awareness: Current awareness score
            
        Returns:
            Entropy drift value (-1.0 to 1.0)
        """
        try:
            s = get_state()
            
            # Calculate change rates
            unity_change = unity - s.unity if s.unity > 0 else 0
            awareness_change = awareness - s.awareness if s.awareness > 0 else 0
            
            # Entropy increases with rapid changes and decreases with stability
            change_magnitude = abs(unity_change) + abs(awareness_change)
            
            # Normalize to [-1, 1] range
            max_expected_change = 0.2  # Per tick
            normalized_change = min(1.0, change_magnitude / max_expected_change)
            
            # Positive drift = increasing entropy (chaos), negative = decreasing (stability)
            entropy_direction = 1.0 if change_magnitude > 0.05 else -0.3
            
            return clamp(normalized_change * entropy_direction, -1.0, 1.0)
            
        except Exception as e:
            logger.debug(f"Error calculating entropy drift: {e}")
            return 0.0
    
    def _calculate_consciousness_pressure(self, unity: float, awareness: float, momentum: float) -> float:
        """
        Calculate SCUP consciousness pressure - tension in the consciousness system.
        
        Pressure builds when there's mismatch between unity/awareness levels,
        high momentum with low coherence, or system stress.
        
        Args:
            unity: Current unity score
            awareness: Current awareness score
            momentum: Current momentum
            
        Returns:
            Pressure value (0.0 to 1.0)
        """
        try:
            # Factor 1: Unity-Awareness mismatch creates pressure
            mismatch_pressure = abs(unity - awareness) * 0.5
            
            # Factor 2: High momentum with low coherence creates pressure
            coherence = self._calculate_consciousness_coherence()
            momentum_pressure = abs(momentum) * (1.0 - coherence) * 0.3
            
            # Factor 3: System performance stress
            active_modules = len([r for r in self.module_registry.values() if r.is_active])
            expected_modules = max(3, len(self.module_registry))
            performance_pressure = (1.0 - min(1.0, active_modules / expected_modules)) * 0.2
            
            # Combine pressures
            total_pressure = mismatch_pressure + momentum_pressure + performance_pressure
            
            return clamp(total_pressure, 0.0, 1.0)
            
        except Exception as e:
            logger.debug(f"Error calculating consciousness pressure: {e}")
            return 0.0
    
    def _calculate_scup_coherence(self) -> float:
        """
        Calculate SCUP-specific coherence measure.
        
        SCUP coherence focuses on protocol-level synchronization and
        communication quality between consciousness modules.
        
        Returns:
            SCUP coherence score (0.0 to 1.0)
        """
        try:
            # Factor 1: Module synchronization quality
            sync_quality = 0.0
            if self.module_registry:
                active_count = len([r for r in self.module_registry.values() if r.is_active])
                sync_quality = active_count / len(self.module_registry)
            
            # Factor 2: Communication bus efficiency
            bus_efficiency = 0.0
            if self.consciousness_bus:
                try:
                    bus_metrics = self.consciousness_bus.get_bus_metrics()
                    bus_efficiency = bus_metrics.get('consciousness_coherence', 0.0)
                except:
                    pass
            
            # Factor 3: Tick execution consistency
            execution_consistency = 0.0
            if self.execution_history:
                recent_times = [h.get('execution_time', 0) for h in list(self.execution_history)[-5:]]
                if recent_times:
                    avg_time = sum(recent_times) / len(recent_times)
                    time_variance = sum((t - avg_time) ** 2 for t in recent_times) / len(recent_times)
                    execution_consistency = max(0.0, 1.0 - (time_variance * 100))  # Scale variance
            
            # Weighted combination
            scup_coherence = (
                sync_quality * 0.4 +
                bus_efficiency * 0.4 +
                execution_consistency * 0.2
            )
            
            return clamp(scup_coherence, 0.0, 1.0)
            
        except Exception as e:
            logger.debug(f"Error calculating SCUP coherence: {e}")
            return 0.0


def demo_tick_orchestrator():
    """Demonstrate tick orchestrator functionality."""
    print("ðŸŽ¼ " + "="*60)
    print("ðŸŽ¼ DAWN TICK ORCHESTRATOR DEMO")
    print("ðŸŽ¼ " + "="*60)
    print()
    
    # Create mock components
    class MockModule:
        def __init__(self, name):
            self.name = name
            self.state = {'coherence': 0.7, 'last_update': time.time()}
        
        def get_tick_state(self):
            return self.state.copy()
        
        def tick_update(self, context):
            self.state['last_update'] = time.time()
            return {'updated': True}
        
        def verify_synchronization(self):
            return True
    
    class MockConsciousnessBus:
        def __init__(self):
            self.events = []
        
        def register_module(self, name, capabilities, schema):
            return True
        
        def broadcast_event(self, event_type, data, source, target_modules=None):
            self.events.append((event_type, data))
            return f"event_{len(self.events)}"
    
    class MockConsensusEngine:
        def request_decision(self, decision_type, context, **kwargs):
            return f"decision_{time.time()}"
        
        def get_recent_decisions(self, limit):
            return []
    
    # Initialize orchestrator
    mock_bus = MockConsciousnessBus()
    mock_consensus = MockConsensusEngine()
    orchestrator = TickOrchestrator(mock_bus, mock_consensus)
    
    print(f"âœ… Tick Orchestrator initialized: {orchestrator.orchestrator_id}")
    print()
    
    # Register test modules
    test_modules = [
        ('entropy_analyzer', MockModule('entropy_analyzer')),
        ('owl_bridge', MockModule('owl_bridge')),
        ('memory_router', MockModule('memory_router')),
        ('symbolic_anatomy', MockModule('symbolic_anatomy'))
    ]
    
    for module_name, module_instance in test_modules:
        success = orchestrator.register_module(
            module_name, 
            module_instance,
            priority=2,
            timeout_seconds=1.0
        )
        print(f"ðŸ“ Registered {module_name}: {'âœ…' if success else 'âŒ'}")
    
    print()
    
    # Execute unified tick
    print("ðŸŽ¼ Executing unified tick...")
    tick_result = orchestrator.execute_unified_tick()
    
    print(f"âœ… Tick #{tick_result.tick_number} completed")
    print(f"   Execution Time: {tick_result.total_execution_time:.3f}s")
    print(f"   Consciousness Coherence: {tick_result.consciousness_coherence:.3f}")
    print(f"   Synchronization: {'âœ…' if tick_result.synchronization_success else 'âŒ'}")
    print(f"   State Consistency: {tick_result.state_consistency_score:.3f}")
    print()
    
    # Show phase breakdown
    print("ðŸ“Š Phase Execution Breakdown:")
    for phase, module_results in tick_result.phase_results.items():
        successful = len([r for r in module_results.values() if r.status == ModuleTickStatus.COMPLETED])
        total_time = sum(r.execution_time for r in module_results.values())
        print(f"   {phase.value}: {successful}/{len(module_results)} modules, {total_time:.3f}s")
    
    print()
    
    # Show performance summary
    perf = tick_result.performance_summary
    print("âš¡ Performance Summary:")
    print(f"   Total Time: {perf['total_execution_time']:.3f}s")
    print(f"   Bottlenecks: {len(tick_result.bottlenecks_detected)}")
    if tick_result.bottlenecks_detected:
        for bottleneck in tick_result.bottlenecks_detected:
            print(f"      - {bottleneck}")
    
    print()
    
    # Show orchestrator status
    status = orchestrator.get_orchestrator_status()
    print("ðŸŽ¼ Orchestrator Status:")
    print(f"   Current Phase: {status['current_phase']}")
    print(f"   Total Ticks: {status['tick_count']}")
    print(f"   Success Rate: {status['metrics']['successful_ticks']}/{status['metrics']['total_ticks_executed']}")
    print(f"   Avg Tick Time: {status['metrics']['average_tick_time']:.3f}s")
    print()
    
    print("ðŸŽ¼ Demo complete! Tick orchestrator enables synchronized consciousness cycles.")


def demo_step():
    """
    Demo step size function for sandbox testing.
    
    This function provides a simple step size that can be modified by
    the patch builder for testing consciousness evolution modifications.
    
    Returns:
        float: Step size for consciousness unity/awareness increments
    """
    return 0.03  # Default step size - this value gets patched for testing


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    demo_tick_orchestrator()
